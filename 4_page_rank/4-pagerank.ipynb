{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic PageRank\n",
    "-> work on graphs\n",
    "\n",
    "In this notebook we will see a basic implementation of the PageRank algorithm, along with some considerations on the complexity. The graphs has been taken from the SNAP (Stanford Large Network Dataset) collection:\n",
    "\n",
    "https://snap.stanford.edu/data/ : dataset with several types of networks, both directed and undirected + libraries of tools (eg. SNAP has implement algorithms to analyze graphs, even the page rank -but we will implement it from zero)\n",
    "\n",
    "We will start with a small directed graph called \"email-Eu-core network\" (https://snap.stanford.edu/data/email-Eu-core.html). It represents the emails sent from user  *i*  to user  *j* (during an observation period). In case of emails with multiple recipients, there is an edge for each recipient. The graph contains 1005 nodes and 25571 edges. There are communities: in the graph we can observe that some nodes are more connnected than others -> identify communities where node have an average number of links higher than outside.\n",
    "\n",
    "The format is very simple: each line contains an edge **from** one node **to** another node (since it's directed I have a starting node and an ending one)\n",
    "```text\n",
    "0 1\n",
    "2 3\n",
    "2 4\n",
    "5 6\n",
    "5 7\n",
    "8 9\n",
    "10 11\n",
    "```\n",
    "-> every line is an edge. The list has the 1005 identifier for the nodes, but idk if they are in a sequence (from 0 to 1004)! So I keep a dictionary of them and map the identifier used in the file om the identifier used internally for the nodes and edges -> if the identifier are sequential, in the matrix they can be an index!\n",
    "\n",
    "From the list, I want to get a square matrix with 1 on column i and row j if ther is a link between node i and j + i has a number of outgoing links equal to d_i.\n",
    "\n",
    "We first load the data as a list of lists (each line becomes a list with 2 elements), then we will transform the data into a matrix and work with the matrix formulation. After that, we  will transform the data into adjacency list, to improve the efficiency and we reformulate the PageRank accordingly. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test an algorithm: find a smaller dataset (=snapshot) to test it and then move to a bigger one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diamater of a graph tend to be low, even in big dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "\n",
    "As usual, we first define the function to load the data, adapting such a function to the specific file input format.\n",
    "\n",
    "In particular, we are going to assign to nodes progressive numbers, so we do not need to rely on the numbering in the file itself (and the node id can be used as matrix index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    input_lines = []\n",
    "    raw_lines = open(filename, 'r').read().splitlines() # Read all lines and put them in a list\n",
    "    num_nodes = 0 # Counter\n",
    "    nodes = {} # Dictionary of identifier of list and the one I assigned\n",
    "    for line in raw_lines:\n",
    "        line_content = line.split() # Each line has two values, so I split them\n",
    "        from_id = int(line_content[0]) # First node (as int)\n",
    "        to_id = int(line_content[1]) # Second node (as int)\n",
    "        if from_id not in nodes:\n",
    "            nodes[from_id] = num_nodes # Map identifier with internal sequential identifier\n",
    "            num_nodes += 1\n",
    "        if to_id not in nodes:\n",
    "            nodes[to_id] = num_nodes\n",
    "            num_nodes += 1\n",
    "        input_lines.append([nodes[from_id], nodes[to_id]]) # Create my list, where each sublist is a pair of nodes with a link\n",
    "    return input_lines, num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file containing the dataset is called \"4-email-Eu-core.txt\".\n",
    "\n",
    "On Colab, remember to mount your Drive\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "input_file = \"/content/drive/My Drive/...\"\n",
    "```\n",
    "Let's load our dataset and see its initial content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset contains 1005 nodes and 25571 edges.\n",
      "\n",
      "The first five edges are: [[0, 1], [2, 3], [2, 4], [5, 6], [5, 7]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_file = \"./4-email-Eu-core.txt\"\n",
    "\n",
    "input_edges, num_nodes = load_data(input_file) # Load data\n",
    "\n",
    "print(\"\\nThe dataset contains\", num_nodes, \"nodes and\", # The result is the list of edges (=sublist) + number of nodes\n",
    "      len(input_edges),\"edges.\\n\")\n",
    "print(\"The first five edges are:\", input_edges[:5],\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix formulation\n",
    "\n",
    "Building and maintaining in memory the full adjacency matrix is inefficient, since the matrix is sparse. But working with a matrix is more intuitive, therefore we will start with this approach. \n",
    "\n",
    "As done before, we will use the Numpy library for handling matrixes. We first fill the matrix with \"1\" if there is an edge, then we will transform the matrix into a column stochastic one.\n",
    "\n",
    "Once I have the matrix formulation. I can use the power iteration method:\n",
    "r^(i+1) = M r^(i)\n",
    "\n",
    "The matrix has to be column stochastics in order to not have leaks! So I fill the columns with 1/N (where N is the number of nodes)\n",
    "\n",
    "?????? min 24 fin 26.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 2.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create an NxN matrix of zeros, where N = number of nodes \n",
    "matrix_nodes = np.zeros((num_nodes, num_nodes)) # That's why I returned the number of nodes above\n",
    "\n",
    "# Set element i,j to \"1\" if there is an edge from j to i\n",
    "for edge in input_edges: # For each elemnt of the list I read the from i and to j -> put a 1 in row j and column i\n",
    "    from_id = edge[0]\n",
    "    to_id = edge[1]\n",
    "    matrix_nodes[to_id, from_id] = 1 # Matrix filled with 1\n",
    "    \n",
    "# compute the \"sparsity\", i.e., percentage of non-zero cells\n",
    "sparsity = 100*float(np.count_nonzero(matrix_nodes))/float(num_nodes*num_nodes) # Computed for statistics\n",
    "print(\"Sparsity: %.2f%%\" % (sparsity))\n",
    "\n",
    "# Show a snippet of the matrix\n",
    "matrix_nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could have guessed the sparsity knowing the matrix has dimension 10^6 + 25k edges and 1K nodes -> 25k/10^6= 25.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize each element with the sum of the column. If the column has no entry (i.e., no outgoing links, it's a dead-end), we fill each element with 1/N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.43902439e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.95024876e-04, 0.00000000e+00, 9.95024876e-04],\n",
       "       [2.43902439e-02, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.95024876e-04, 0.00000000e+00, 9.95024876e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.19047619e-02, ...,\n",
       "        9.95024876e-04, 0.00000000e+00, 9.95024876e-04],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.95024876e-04, 0.00000000e+00, 9.95024876e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.95024876e-04, 0.00000000e+00, 9.95024876e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.95024876e-04, 0.00000000e+00, 9.95024876e-04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the matrix: first I check if there is at least a value different from zero in each column\n",
    "for col in range(num_nodes):\n",
    "    degree = np.sum(matrix_nodes[:,col])  \n",
    "    if degree > 0: # For each column, take the sum of its values: if it's >0 there is at least a 1, I have to normalize -> 1/d_i\n",
    "        matrix_nodes[:,col] *= 1.0/degree\n",
    "    else:\n",
    "        matrix_nodes[:,col] = 1.0/num_nodes # In this case, I put 1/N\n",
    "\n",
    "# Show a snippet of the normalized matrix\n",
    "matrix_nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary questions\n",
    "\n",
    "PRIMI 10 MIN 15/05\n",
    "\n",
    "### Question  Q1\n",
    "<div class=\"alert alert-info\">\n",
    "Consider the matrix before the normalization: compute the number of dead-end nodes (and its percentage with respect to the total number of nodes).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dead-end nodes = column sum up to 0 = column has no 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q2\n",
    "<div class=\"alert alert-info\">\n",
    "Compute the sparsity of the matrix (before and after normalization), i.e., the ratio between the non-zero elements and the total number of elements.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q3\n",
    "<div class=\"alert alert-info\">\n",
    "Compute the amount of memory (bytes) required to store the matrix, before and after the normalization (then I will check with the adjency list too -> for larger dataset the memory is not enough to store the matrix, so I have to use the list)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q4\n",
    "<div class=\"alert alert-info\">\n",
    "Compute some basic statistics about the graph, such as:\n",
    "    \n",
    "- minimum, maximum and average outdegree (number of outgoing links);\n",
    "- outdegree distribution (percentage of nodes with outdegree 0, 1, 2, 3, ...): graph with number of nodes that have 0 links, then 1, then etc (histogram)\n",
    "- minimum, maximum and average indegree (number of incoming links);\n",
    "- indegree distribution (percentage of nodes with indegree 0, 1, 2, 3, ...): can be different from the outdegree distribution\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a feeling of the statistic of the dataset \n",
    "# adg_matrix is the matrix with NO normalization\n",
    "\n",
    "# nz_indexes is a data structure that contains the indexes of non-zero values\n",
    "# [-1] is the last element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't plot up to the last value, but  focus for the first 100\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding to 0 are the dead-end nodes (highest number of nodes), with an high putdegree I get less and less nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the indegree, summing over columns and not rows now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect the same average, but min and max different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the 1 has the most nodes, not 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagerank (matrix formulation)\n",
    "\n",
    "We are now ready to compute the Pagerank with the power iteration approach. The inputs are:\n",
    "\n",
    "- The adjacency matrix;\n",
    "- The teleport parameter beta;\n",
    "- The target error;\n",
    "- The maximum number of iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the powe iteration method (with beta): as input I have the matrix itself -> there are no dead end since I replaced empty\n",
    "# values with 1/N; but I may have spder traps, so I use teleport\n",
    "def matrix_pagerank(input_matrix, beta, target_error, max_iterations): # max_iterations is a stop condition: from the theory I hould stop when the ranking of i+1 is equal to the rank of i\n",
    "    #                                                                    -> I have reached a stable situation. But there I have numerical approximation, so this never hapens! I have to limit\n",
    "    #                                                                    the number of iterations.\n",
    "    #                                                                    I also have target_error to reach a stable solution: whatever happen first, I stop :)\n",
    "    # Since the matrix is an input, I can infer the number of nodes from the matrix size\n",
    "    num_nodes = input_matrix.shape[0]\n",
    "    # Initialize the ranking vector, it's r^(i)\n",
    "    # Shape of vector = number of nodes\n",
    "    rank_prev = np.full((num_nodes), 1.0/num_nodes) # Create initial ranking with 1/N assigned to all nodes\n",
    "    # Iterate at most \"max_iterations\" times\n",
    "    for curr_iteration in range(max_iterations):\n",
    "        # It's r^(i+1)\n",
    "        rank_new = beta*input_matrix.dot(rank_prev) + (1.0-beta)/num_nodes # All operation on vectors or matrixes -> I get a new vector at the end\n",
    "        # Compute the error\n",
    "        curr_err = np.sum(abs(rank_new - rank_prev)) # Sum up all elements\n",
    "        # For debugging: print the error at each iteration \n",
    "        print(\"iteration:\", curr_iteration, \", err:\", curr_err)\n",
    "        if curr_err < target_error: # If I reach the target error I stop, otherwise I do iterations until max_iterations (but I always stop)\n",
    "            break\n",
    "        # Note the \".copy()\", otherwise they end up to be the same vector (=override)\n",
    "        rank_prev = rank_new.copy()\n",
    "    return rank_new, curr_err, curr_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the PageRank with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 , err: 0.4982592433502846\n",
      "iteration: 1 , err: 0.11132642279660003\n",
      "iteration: 2 , err: 0.02938698563919208\n",
      "iteration: 3 , err: 0.011919997309565854\n",
      "iteration: 4 , err: 0.006469027782158059\n",
      "iteration: 5 , err: 0.0044034387718768705\n",
      "iteration: 6 , err: 0.003182390530861841\n",
      "iteration: 7 , err: 0.002358449708309306\n",
      "iteration: 8 , err: 0.001801200071351313\n",
      "iteration: 9 , err: 0.0013987204734422808\n",
      "iteration: 10 , err: 0.001095372908458477\n",
      "iteration: 11 , err: 0.0008663391375282711\n",
      "iteration: 12 , err: 0.0006876723577637379\n",
      "iteration: 13 , err: 0.0005459417455002378\n",
      "iteration: 14 , err: 0.0004334705824646937\n",
      "iteration: 15 , err: 0.00034419929815731904\n",
      "iteration: 16 , err: 0.00027333072070186333\n",
      "iteration: 17 , err: 0.00021706422712188943\n",
      "iteration: 18 , err: 0.00017238690049600547\n",
      "iteration: 19 , err: 0.0001369091801939733\n",
      "iteration: 20 , err: 0.00010873521913732417\n",
      "iteration: 21 , err: 8.636047538247281e-05\n",
      "\n",
      "Computed 21 iterations with final error 8.636047538247281e-05 \n",
      "\n",
      "[0.00127608 0.00743391 0.00204666 ... 0.0002516  0.00025427 0.00025765]\n"
     ]
    }
   ],
   "source": [
    "beta = 0.8\n",
    "error = 0.0001\n",
    "max_iterations = 30\n",
    "\n",
    "pg_nodes, err, iterations = matrix_pagerank(matrix_nodes, beta, error, max_iterations)\n",
    "print(\"\\nComputed\", iterations, \"iterations with final error\", err, \"\\n\")\n",
    "print(pg_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I do more iterations, the error decrease.\n",
    "\n",
    "???? min 50 fin min 54\n",
    "\n",
    "Inspecting the rank help understand if the rank was set corectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q5\n",
    "<div class=\"alert alert-info\">\n",
    "Modify the function so that the error is not an absolute value (such as 0.0001), but a relative one for each node rank. For instance, one could stop the iterations if, for each node, the variation of the rank is below 1% with respect to the previous rank.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error goes from absolute value to percentage: at each iteration for each row (=node) the error must be lower than 1%.\n",
    "# If all rankings of the nodes are <1%, indipendently from the rank, I can stop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency list formulation\n",
    "\n",
    "This formulation requires the whole matrix! If no memory -> adjacency list. Instead of a matrix, we maintain a data structure (dicionary) in which, for each node (key), we have a list of neighbors (value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 5, 6, 17, 18, 64, 73, 74, 88, 101, 103, 146, 148, 166, 177, 178, 215, 218, 221, 222, 223, 226, 238, 248, 250, 266, 268, 283, 297, 309, 313, 316, 368, 377, 380, 459, 498, 560, 581, 734]\n"
     ]
    }
   ],
   "source": [
    "adj_nodes = {} # list of neighbors as a dictionary\n",
    "for edge in input_edges: # Go through the list of edges I computed at the start\n",
    "    from_id = edge[0] # From node\n",
    "    to_id = edge[1]\n",
    "    # ???? MIN 57 fin 5\n",
    "    if from_id not in adj_nodes:\n",
    "        adj_nodes[from_id] = [to_id]\n",
    "    else:\n",
    "        adj_nodes[from_id].append(to_id)\n",
    "\n",
    "# For simplicity, we sort each value (not necessary, but better for visualization)\n",
    "for node in adj_nodes:\n",
    "    adj_nodes[node].sort()\n",
    "\n",
    "# Show the neighbors of the first node\n",
    "print(adj_nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now change our Pagerank formulation considering as input the adjacency list. Note that, differently from the matrix, we need to explicitly indicate the number of nodes, beacuse nodes with no outgoing links (dead-ends) do not appear (as key) in the adjacency list and we cannot not infer from the size of the list the number of nodes.\n",
    "\n",
    "Note also that we evaluate at each step how much ranking has been lost (due to dead-ends), and we reintegrate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a node, for the PR we consider the incoming links. But the adj list has the outgoing list, so I build the rank incrementally.\n",
    "# Also, a node with no outgoing links is not gonna appear in my adj list! Then the lost vector will be in the vector and have a rank,\n",
    "# but that ranking will be not distributed and will be lost. To solve this, I start from a ranking equal to 1 and subtracts the previous\n",
    "# ranks computed -> at the end I will know which rank was lost ????? MIN 1.05\n",
    "def adj_pagerank(adj_list, num_nodes, beta, target_error, max_iterations): # num_nodes is to build an empty vector of that size\n",
    "    # Initialize the ranking vector with 1/N\n",
    "    rank_prev = np.full((num_nodes), 1.0/num_nodes)\n",
    "    # Iterate at most \"max_iterations\" times\n",
    "    for curr_iteration in range(max_iterations):\n",
    "        # since rank_new is incrementally built every time, it has to be initialized\n",
    "        rank_new = np.zeros((num_nodes)) # start from 0 and add incrementally all the values, going element by element\n",
    "        # The leaked ranking is found decrementally\n",
    "        leaked = 1.0 # start from here and for each node we substract from it: the fraction remaining at the end is the node lost\n",
    "        for node in adj_list:\n",
    "            # We derive the outdegree from the list size\n",
    "            outdegree = len(adj_list[node])\n",
    "            leaked -= rank_prev[node]\n",
    "            for neigh in adj_list[node]:\n",
    "                rank_new[neigh] += beta*rank_prev[node]/outdegree # Update incrementally\n",
    "        # Add the teleport (1-beta) and the leaked values (times beta)\n",
    "        rank_new += (1.0-beta+beta*leaked)/num_nodes\n",
    "        # Compute the error\n",
    "        curr_err = np.sum(abs(rank_new - rank_prev))\n",
    "        if curr_err < target_error:\n",
    "            break\n",
    "        rank_prev = rank_new.copy()\n",
    "    return rank_new, curr_err, curr_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it and compare with the results obtained with the matrix formulation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computed 21 iterations with final error 8.636047538305758e-05 \n",
      "\n",
      "[0.00127608 0.00743391 0.00204666 ... 0.0002516  0.00025427 0.00025765]\n",
      "\n",
      "The sum of the element-wise difference with the previous formulation is:\n",
      " 1.2421704290166424e-15 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pg_nodes_adj, err, iterations = adj_pagerank(adj_nodes, num_nodes, beta, error, max_iterations)\n",
    "print(\"\\nComputed\", iterations, \"iterations with final error\", err, \"\\n\")\n",
    "print(pg_nodes_adj)\n",
    "\n",
    "print(\"\\nThe sum of the element-wise difference with the previous formulation is:\\n\", \n",
    "      np.sum(abs(pg_nodes_adj - pg_nodes)), \"\\n\") # check that the 2 formulations are similar enough (Not 0 due to precision errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional questions\n",
    "\n",
    "### Question  Q6\n",
    "<div class=\"alert alert-info\">\n",
    "Compute the amount of memory (bytes) required to store the adjacency list, and compare it with the memory used by the matrix. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory used by the matrix is in Q3, get the mem of the adj list in the same way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw memory for the adj list is WAY less than the matrix (which is more intuitive though)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q7\n",
    "<div class=\"alert alert-info\">\n",
    "Find the top 5 ranked nodes, the bottom 5 ranked nodes, and compute the ranking range (difference between the highest and lowest ranking).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sense of the values computed\n",
    "\n",
    "# [i] get the top node, [-(i+1)] the corresponding bottom node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q8\n",
    "<div class=\"alert alert-info\">\n",
    "Divide the different ranking values into ranges (with constant size, or exponentially increasing size) and show the percentage of nodes in each range. \n",
    "    \n",
    "Compare the distribution with the indegree distribution computed before.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the values in range and count how many nodes in each range -> can plot this\n",
    "# I divide in 100 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q9\n",
    "<div class=\"alert alert-info\">\n",
    "Analyze a larger graph (file \"4-soc-Epinions1.txt\"), and in particular:\n",
    "    \n",
    "- How many nodes and edges does it have?\n",
    "- Is your system able to handle the PageRank computation using the matrix formulation?\n",
    "- Compute the PageRank with the adjancency list formulation.\n",
    "- Reply to Q7-Q8 for this graph.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question  Q10\n",
    "<div class=\"alert alert-info\">\n",
    "Can you reformulate the PageRank algorithm assuming to have the adjacency list of the incoming links? \n",
    "    \n",
    "Does this formulation has benefits?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
